//! This example shows how to create a custom render pass that runs after the main pass
//! and reads the texture generated by the main pass.
//!
//! The example shader is a very simple implementation of chromatic aberration.
//! To adapt this example for 2D, replace all instances of 3D structures (such as `Core3D`, etc.) with their corresponding 2D counterparts.
//!
//! This is a fairly low level example and assumes some familiarity with rendering concepts and wgpu.

mod mem;

use ash::vk;
use bevy::{
    core_pipeline::core_3d::graph::{Core3d, Node3d},
    ecs::query::QueryItem,
    prelude::*,
    render::{
        RenderApp,
        extract_component::{
            DynamicUniformIndex, ExtractComponent, ExtractComponentPlugin, UniformComponentPlugin,
        },
        render_graph::{
            NodeRunError, RenderGraphApp, RenderGraphContext, RenderLabel, ViewNode, ViewNodeRunner,
        },
        render_resource::*,
        renderer::RenderContext,
        view::ViewTarget,
    },
};
use pyo3::ToPyObject;
use pyo3::prelude::{PyAnyMethods, PyDictMethods, PyModule};
use pyo3::types::PyDict;
use std::ffi::CString;
use std::sync::Arc;
use ash::vk::{DeviceCreateInfo, DeviceQueueCreateInfo};

/// This example uses a shader source file from the assets subdirectory
const SHADER_ASSET_PATH: &str = "assets/test.py";

/// It is generally encouraged to set up post processing effects as a plugin
pub struct CudaPlugin;

impl Plugin for CudaPlugin {
    fn build(&self, app: &mut App) {
        // We need to get the render app from the main app
        let Some(render_app) = app.get_sub_app_mut(RenderApp) else {
            return;
        };

        render_app
            // Bevy's renderer uses a render graph which is a collection of nodes in a directed acyclic graph.
            // It currently runs on each view/camera and executes each node in the specified order.
            // It will make sure that any node that needs a dependency from another node
            // only runs when that dependency is done.
            //
            // Each node can execute arbitrary work, but it generally runs at least one render pass.
            // A node only has access to the render world, so if you need data from the main world
            // you need to extract it manually or with the plugin like above.
            // Add a [`Node`] to the [`RenderGraph`]
            // The Node needs to impl FromWorld
            //
            // The [`ViewNodeRunner`] is a special [`Node`] that will automatically run the node for each view
            // matching the [`ViewQuery`]
            .add_render_graph_node::<ViewNodeRunner<CudaNode>>(
                // Specify the label of the graph, in this case we want the graph for 3d
                Core3d, // It also needs the label of the node
                CudaLabel,
            )
            .add_render_graph_edges(
                Core3d,
                // Specify the node ordering.
                // This will automatically create all required node edges to enforce the given ordering.
                (
                    Node3d::Tonemapping,
                    CudaLabel,
                    Node3d::EndMainPassPostProcessing,
                ),
            );
    }

    fn finish(&self, app: &mut App) {
        // We need to get the render app from the main app
        let Some(render_app) = app.get_sub_app_mut(RenderApp) else {
            return;
        };

        render_app.insert_resource(CudaDevice(cudarc::driver::CudaDevice::new(0).unwrap()));
    }
}

#[derive(Resource, Deref, DerefMut)]
pub struct CudaDevice(Arc<cudarc::driver::CudaDevice>);

#[derive(Debug, Hash, PartialEq, Eq, Clone, RenderLabel)]
struct CudaLabel;

// The post process node used for the render graph
#[derive(Default)]
struct CudaNode;

// The ViewNode trait is required by the ViewNodeRunner
impl ViewNode for CudaNode {
    // The node needs a query to gather data from the ECS in order to do its rendering,
    // but it's not a normal system so we need to define it manually.
    //
    // This query will only run on the view entity
    type ViewQuery = (&'static ViewTarget,);

    // Runs the node logic
    // This is where you encode draw commands.
    //
    // This will run on every view on which the graph is running.
    // If you don't want your effect to run on every camera,
    // you'll need to make sure you have a marker component as part of [`ViewQuery`]
    // to identify which camera(s) should run the effect.
    fn run(
        &self,
        _graph: &mut RenderGraphContext,
        render_context: &mut RenderContext,
        (view_target,): QueryItem<Self::ViewQuery>,
        world: &World,
    ) -> Result<(), NodeRunError> {
        let cuda_device = world.resource::<CudaDevice>();
        unsafe {
            render_context
                .render_device()
                .wgpu_device()
                .as_hal::<wgpu::hal::api::Vulkan, _, _>(|device| {
                    let Some(device) = device else {
                        panic!("Failed to get Vulkan device");
                    };

                    let image = view_target
                        .main_texture()
                        .as_hal::<wgpu::hal::api::Vulkan, _, _>(|image| {
                            let Some(image) = image else {
                                panic!("Failed to get Vulkan image");
                            };
                            image.raw_handle()
                        });

                    let instance = device.shared_instance().raw_instance();
                    let physical_device = device.raw_physical_device();
                    let device = device.raw_device();
                    let image_width = view_target.main_texture().width();
                    let image_height = view_target.main_texture().height();

                    println!("Processing image with CUDA...");

                    let res = mem::with_vk_cuda_buffer(
                        instance,
                        device,
                        physical_device,
                        image,
                        image_width,
                        image_height,
                        vk::Format::R8G8B8A8_SRGB, // Rgba8UnormSrgb in wgpu
                        0,
                        0,
                        |py, cuda_array| {
                            let text = std::fs::read_to_string(SHADER_ASSET_PATH).unwrap();
                            let module = PyModule::from_code(
                                py,
                                CString::new(text).unwrap().as_c_str(),
                                c"bevy_cuda_script.py",  // A meaningful file name
                                c"bevy_cuda_module",     // A meaningful module name
                            )?;

                            let res = module.getattr("process_image")?.call1((cuda_array,))?;
                            println!("CUDA processing result: {:?}", res);

                            Ok(())
                        },
                    );

                    if let Err(err) = res {
                        eprintln!("CUDA processing failed: {:?}", err);
                    }
                });
        }

        Ok(())
    }
}
